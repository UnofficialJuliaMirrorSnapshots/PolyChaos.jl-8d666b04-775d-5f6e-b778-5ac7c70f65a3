{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galerkin-based Solution of Random Differential Equation\n",
    "\n",
    "This tutorial demonstrates how random differential equations can be solved using polynomial chaos expansions (PCE).\n",
    "\n",
    "## Theory\n",
    "\n",
    "A random differential equation is an ordinary differential equation that has random parameters, hence its solution is itself a (time-varying) random variable.\n",
    "Perhaps the simplest non-trivial example is the following scalar, linear ordinary differential equation\n",
    "$$\n",
    "\\dot{x}(t) = a x(t), \\quad x(0) = x_{0},\n",
    "$$\n",
    "where $a$ is the realization of a Gaussian random variable $\\mathsf{a} \\sim \\mathcal{N}(\\mu, \\sigma^2)$ with mean $\\mu$ and variance $\\sigma^2$.\n",
    "Arguably, for every realization $a$ we can solve the differential equation and obtain\n",
    "$$\n",
    "x(t) = x_0 \\mathrm{e}^{a t},\n",
    "$$\n",
    "from which we find that\n",
    "$$\n",
    "\\ln (x(t)) = \\ln (x_0) + at \\sim \\mathcal{N}(\\ln(x_0) + \\mu t, (\\sigma t)^2).\n",
    "$$\n",
    "In other words, the logarithm of the solution is normally distributed (so-called [log-normal distribution](https://en.wikipedia.org/wiki/Log-normal_distribution)).\n",
    "\n",
    "We'd like to obtain this result numerically with the help of PCE.\n",
    "The first step is to define the (truncated) PCE for the random variable $\\mathsf{a}$\n",
    "$$\n",
    "\\mathsf{a} = \\sum_{i=0}^{L} a_i \\phi_i,\n",
    "$$\n",
    "where $a_i$ are the so-called PCE coefficients, and $\\phi_i$ are the orthogonal basis polynomials.\n",
    "As the solution to the random differential equation is itself a random variable, we treat $x(t)$ as the realization of the random variable $\\mathsf{x}(t)$, and define its PCE\n",
    "$$\n",
    "\\mathsf{x}(t) = \\sum_{i=0}^{L} x_i(t) \\phi_i.\n",
    "$$\n",
    "The question is how to obtain the unknown PCE coefficients $x_i(t)$ from the known PCE coefficients $a_i$ relative to the orthogonal basis polynomials $\\phi_i$.\n",
    "This can be done using Galerkin projection, which is nothing else than projecting onto the orthogonal basis.\n",
    "Think of a three-dimensional space, in which you have placed some three-dimensional object.\n",
    "If you know project the silhouett of the object onto every axis of the three-dimensional space, then you are doing a Galerkin projection.\n",
    "With PCE the concept is equivalent, but the imagination has a harder time.\n",
    "The first step for Galerkin projection is to insert the PCEs\n",
    "$$\n",
    "\\sum_{i=0}^{L} \\dot{x}_i(t) \\phi_i = \\sum_{j=0}^{L} a_j \\phi_j \\sum_{k=0}^{L} x_k(t) \\phi_k;\n",
    "$$\n",
    "the second step is to project onto every basis polynomial $\\phi_m$ for $m = 0, 1, \\dots, L$, and to exploit orthogonality of the basis.\n",
    "This gives\n",
    "$$\n",
    "\\dot{x}_m(t) \\langle \\phi_m, \\phi_m \\rangle = \\sum_{j=0}^{L} \\sum_{k=0}^{L} a_j x_k(t) \\langle \\phi_l \\phi_k, \\phi_m \\rangle \\quad m = 0, 1, \\dots, L.\n",
    "$$\n",
    "Of course, the initial condition must not be forgotten:\n",
    "$$\n",
    "x_0(0) = x_0, \\quad x_m(0) = 0 \\quad m = 1, \\dots, L.\n",
    "$$\n",
    "If we can solve this enlarged system of ordinary random differential equations, we can reconstruct the analytic solution.\n",
    "\n",
    "## Practice\n",
    "We begin by defining the random differential equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 2.0\n",
    "μ, σ = -0.5, 0.05 \n",
    "tend, Δt = 3.0, 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define an orthogonal basis (and its quadrature rule) relative to the Gaussian measure using `PolyChaos`.\n",
    "We choose a maximum degree of `L`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PolyChaos\n",
    "L, Nrec = 6, 40\n",
    "opq = OrthoPolyQ(\"gaussian\",L;Nrec=Nrec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the PCE for $\\mathsf{a}$ and solve the Galerkin-projected ordinary differential equation using `DifferentialEquations.jl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DifferentialEquations\n",
    "\n",
    "a = [ convert2affinePCE(\"gaussian\",μ,σ); zeros(Float64,L-1) ] # PCE coefficients of a\n",
    "xinit = [ x0; zeros(Float64,L) ] # PCE coefficients of initial condition\n",
    "\n",
    "t2 = Tensor(2,opq); # \\langle \\phi_i, \\phi_j \\rangle\n",
    "t3 = Tensor(3,opq); # \\langle \\phi_i \\phi_j, \\phi_k \\rangle\n",
    "\n",
    "# Galerkin-projected random differential equation\n",
    "function ODEgalerkin(du,u,p,t)\n",
    "   du[:] = [ sum( p[j+1]*u[k+1]*t3.get([j,k,m])/t2.get([m,m]) for j=0:L for k=0:L) for m=0:L ] \n",
    "end\n",
    "\n",
    "probgalerkin = ODEProblem(ODEgalerkin,xinit,(0,tend),a)\n",
    "solgalerkin = solve(probgalerkin;saveat=0:Δt:tend)\n",
    "t, x = solgalerkin.t, solgalerkin.u;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For later purposes we compute the expected value and the standard deviation at all time instants using PCE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an advantage of PCE is that moments can be computed from the PCE coefficients alone; no sampling required\n",
    "mean_pce = [ mean(x[i],opq) for i=1:length(x)]  \n",
    "std_pce = [ std(x[i],opq) for i=1:length(x) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare the solution from PCE to a Monte-Carlo-based solution.\n",
    "That means to solve the ordinary differential equation for many samples of $\\mathsf{a}$.\n",
    "We first sample from the measure using `sampleMeasure`, and then generate samples of $\\mathsf{a}$ using `evaluatePCE`.\n",
    "After that we solve the ODE and store the results in `xmc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics\n",
    "Nsmpl = 5000\n",
    "ξ = sampleMeasure(Nsmpl,opq)     # sample from Gaussian measure; effectively randn() here    \n",
    "asmpl = evaluatePCE(a,ξ,opq)     # sample random variable with PCE coefficients a; effectively μ + σ*randn() here\n",
    "# or: asmpl = samplePCE(Nsmpl,a,opq)\n",
    "xmc = [ solve(ODEProblem((u,p,t)->aa*u,x0,(0,tend));saveat=0:Δt:tend).u for aa in asmpl]\n",
    "xmc = hcat(xmc...);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare the Monte Carlo mean and standard deviation to the expression from PCE for every time instant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ mean(xmc,dims=2)-mean_pce std(xmc,dims=2)-std_pce]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the accuracy of PCE deteriorates over time.\n",
    "Possible remedies are to increase the dimension of PCE, and to tweak the tolerances of the integrator.\n",
    "\n",
    "Finally, we compare whether the samples follow a log-normal distribution, and compare the result to the analytic mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logx_pce = [ log.(evaluatePCE(x[i],ξ,opq)) for i=1:length(t)]\n",
    "[mean.(logx_pce)-(log(x0) .+ μ*t) std.(logx_pce)-σ*t ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.7.0",
   "language": "julia",
   "name": "julia-0.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
